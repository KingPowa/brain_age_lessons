{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "61dfe7c5",
      "metadata": {
        "id": "61dfe7c5"
      },
      "source": [
        "From the lesson learnt before, we understood how to train a DL for age prediction\n",
        "\n",
        "We got decent results given our limited model.\n",
        "\n",
        "Now it's your turn:\n",
        "\n",
        "- We assume you don't have a big computational unit\n",
        "- You have full access to the scans\n",
        "- You have full access to the dataset\n",
        "\n",
        "Can you think of a way of improving the pipeline in a manageable way given your constraints?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78e466cf",
      "metadata": {},
      "source": [
        "I will try MLP on corthical thicknesses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "EFEfCH7LOofq",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EFEfCH7LOofq",
        "outputId": "6c87bb2c-35d4-4484-c0c1-7417595a8a95"
      },
      "outputs": [],
      "source": [
        "# !pip install monai==1.5.0 --no-dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "5e621376",
      "metadata": {
        "id": "5e621376"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "# General purpose\n",
        "import os\n",
        "import random\n",
        "import tqdm\n",
        "from typing import List\n",
        "# # DL\n",
        "import torch as th\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "# Data\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "import nibabel as nib\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import monai.transforms as mtr\n",
        "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
        "# Visualize\n",
        "import matplotlib.pyplot as plt\n",
        "import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "ieVJGfNDKzZD",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ieVJGfNDKzZD",
        "outputId": "87de328c-4bc5-4136-c53e-04faac43459f"
      },
      "outputs": [],
      "source": [
        "# We download instead a preprocessed version (will be explained...)\n",
        "# !mkdir ../data\n",
        "# !curl -L -o ../data/preprocessed-ixi-dataset-with-fs8.zip -z ../data/preprocessed-ixi-dataset-with-fs8.zip https://www.kaggle.com/api/v1/datasets/download/kingpowa/preprocessed-ixi-dataset-with-fs8\n",
        "# !unzip -n ../data/preprocessed-ixi-dataset-with-fs8.zip -d ../data\n",
        "# !mkdir ../data/IXI\n",
        "# !mv -v ../data/T1w_Processed_IXI_with_csv/IXI/* ../data/IXI\n",
        "# !rm -rf ../data/preprocessed-ixi-dataset-with-fs8.zip\n",
        "# !rm -rf ../data/T1w_Processed_IXI_with_csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "449bdd4d",
      "metadata": {
        "id": "449bdd4d"
      },
      "outputs": [],
      "source": [
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "yDI2dUz8piVD",
      "metadata": {
        "id": "yDI2dUz8piVD"
      },
      "outputs": [],
      "source": [
        "th.manual_seed(0)\n",
        "random.seed(0)\n",
        "np.random.seed(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "4e220407",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4e220407",
        "outputId": "65963aec-2ff8-4172-8514-c3a624dc97f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "device = th.device('cuda' if th.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "d01f201d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "d01f201d",
        "outputId": "2a9c149c-2bef-4d95-a5b5-a60e6df5e5f6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>subject_id</th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>scanner</th>\n",
              "      <th>site</th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>dataset_name</th>\n",
              "      <th>subject_key</th>\n",
              "      <th>session</th>\n",
              "      <th>run</th>\n",
              "      <th>registered_mni</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>IXI002</td>\n",
              "      <td>35.80</td>\n",
              "      <td>Female</td>\n",
              "      <td>Philips-1.5T</td>\n",
              "      <td>Guy’s-Hospital</td>\n",
              "      <td>Healthy</td>\n",
              "      <td>IXI</td>\n",
              "      <td>IXI002_IXI</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>sub-IXI002/ses-1/run-1/anat/sub-IXI002_acq-Phi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>IXI012</td>\n",
              "      <td>38.78</td>\n",
              "      <td>Male</td>\n",
              "      <td>Philips-3.0T</td>\n",
              "      <td>Hammersmith-Hospital</td>\n",
              "      <td>Healthy</td>\n",
              "      <td>IXI</td>\n",
              "      <td>IXI012_IXI</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>sub-IXI012/ses-1/run-1/anat/sub-IXI012_acq-Phi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>IXI013</td>\n",
              "      <td>46.71</td>\n",
              "      <td>Male</td>\n",
              "      <td>Philips-3.0T</td>\n",
              "      <td>Hammersmith-Hospital</td>\n",
              "      <td>Healthy</td>\n",
              "      <td>IXI</td>\n",
              "      <td>IXI013_IXI</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>sub-IXI013/ses-1/run-1/anat/sub-IXI013_acq-Phi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>IXI014</td>\n",
              "      <td>34.24</td>\n",
              "      <td>Female</td>\n",
              "      <td>Philips-3.0T</td>\n",
              "      <td>Hammersmith-Hospital</td>\n",
              "      <td>Healthy</td>\n",
              "      <td>IXI</td>\n",
              "      <td>IXI014_IXI</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>sub-IXI014/ses-1/run-1/anat/sub-IXI014_acq-Phi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>IXI015</td>\n",
              "      <td>24.28</td>\n",
              "      <td>Male</td>\n",
              "      <td>Philips-3.0T</td>\n",
              "      <td>Hammersmith-Hospital</td>\n",
              "      <td>Healthy</td>\n",
              "      <td>IXI</td>\n",
              "      <td>IXI015_IXI</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>sub-IXI015/ses-1/run-1/anat/sub-IXI015_acq-Phi...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  subject_id    age     sex       scanner                  site diagnosis  \\\n",
              "0     IXI002  35.80  Female  Philips-1.5T        Guy’s-Hospital   Healthy   \n",
              "1     IXI012  38.78    Male  Philips-3.0T  Hammersmith-Hospital   Healthy   \n",
              "2     IXI013  46.71    Male  Philips-3.0T  Hammersmith-Hospital   Healthy   \n",
              "3     IXI014  34.24  Female  Philips-3.0T  Hammersmith-Hospital   Healthy   \n",
              "4     IXI015  24.28    Male  Philips-3.0T  Hammersmith-Hospital   Healthy   \n",
              "\n",
              "  dataset_name subject_key  session  run  \\\n",
              "0          IXI  IXI002_IXI        1    1   \n",
              "1          IXI  IXI012_IXI        1    1   \n",
              "2          IXI  IXI013_IXI        1    1   \n",
              "3          IXI  IXI014_IXI        1    1   \n",
              "4          IXI  IXI015_IXI        1    1   \n",
              "\n",
              "                                      registered_mni  \n",
              "0  sub-IXI002/ses-1/run-1/anat/sub-IXI002_acq-Phi...  \n",
              "1  sub-IXI012/ses-1/run-1/anat/sub-IXI012_acq-Phi...  \n",
              "2  sub-IXI013/ses-1/run-1/anat/sub-IXI013_acq-Phi...  \n",
              "3  sub-IXI014/ses-1/run-1/anat/sub-IXI014_acq-Phi...  \n",
              "4  sub-IXI015/ses-1/run-1/anat/sub-IXI015_acq-Phi...  "
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "masterfile_path = \"../data/IXI/subjects.csv\"\n",
        "masterfile = pd.read_csv(masterfile_path)\n",
        "masterfile = masterfile[masterfile[\"age\"] != -1.0]\n",
        "masterfile.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c70e7421",
      "metadata": {},
      "outputs": [],
      "source": [
        "def grad_norm(model):\n",
        "    \"\"\"Compute total L2 norm of gradients over all parameters.\"\"\"\n",
        "    total_norm = 0.0\n",
        "    for p in model.parameters():\n",
        "        if p.grad is not None:\n",
        "            param_norm = p.grad.data.norm(2).item()\n",
        "            total_norm += param_norm ** 2\n",
        "    return total_norm ** 0.5\n",
        "\n",
        "def train_epoch(model, loader, optimizer, input_label=\"t1n\", loss_fn=None, update=True, log_norm=False, scheduler=None, per_step=False):\n",
        "    # Add per_step for per_step update of scheduler\n",
        "    model.train()\n",
        "    running = 0.0\n",
        "\n",
        "    if log_norm:\n",
        "      grad_norm_sum = 0.0\n",
        "      grad_norm_count = 0\n",
        "      max_grad_norm = 0.0\n",
        "\n",
        "    for batch in tqdm.tqdm(loader):\n",
        "        img = batch[input_label].to(device)\n",
        "        age = batch[\"age\"].to(device).view(-1, 1)\n",
        "        pred = model(img).view(-1, 1)\n",
        "        loss = loss_fn(pred, age)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "\n",
        "        if update:\n",
        "          optimizer.step()\n",
        "          if per_step:\n",
        "             if scheduler is not None:\n",
        "                if isinstance(scheduler, th.optim.lr_scheduler.ReduceLROnPlateau):\n",
        "                    scheduler.step(loss)\n",
        "                else:\n",
        "                    scheduler.step()\n",
        "\n",
        "        else:\n",
        "          loss = loss.detach()\n",
        "        running += loss.item() * img.size(0)\n",
        "\n",
        "        if log_norm:\n",
        "            gn = grad_norm(model)\n",
        "            grad_norm_sum += gn\n",
        "            grad_norm_count += 1\n",
        "            if gn > max_grad_norm:\n",
        "                max_grad_norm = gn\n",
        "        \n",
        "    for param_group in optimizer.param_groups:\n",
        "        lr = param_group['lr']\n",
        "    if log_norm and grad_norm_count > 0:\n",
        "        avg_grad_norm = grad_norm_sum / grad_norm_count\n",
        "    if update:\n",
        "        if not per_step:\n",
        "            if scheduler is not None:\n",
        "                if isinstance(scheduler, th.optim.lr_scheduler.ReduceLROnPlateau):\n",
        "                    scheduler.step(loss)\n",
        "                else:\n",
        "                    scheduler.step()\n",
        "\n",
        "    return running / len(loader.dataset), lr, avg_grad_norm\n",
        "\n",
        "def eval_model(model, loader, input_label=\"cort\", loss_fns={}):\n",
        "    model.eval()\n",
        "    with th.no_grad():\n",
        "        losses = {k:[] for k in loss_fns.keys()}\n",
        "        for batch in loader:\n",
        "            img = batch[input_label].to(device)\n",
        "            age = batch[\"age\"].to(device).view(-1, 1)\n",
        "            pred = model(img).view(-1, 1)\n",
        "            for k in loss_fns.keys():\n",
        "                losses[k].append(loss_fns[k](pred, age).cpu().numpy())\n",
        "        losses = {k: np.concatenate(val) for k, val in losses.items()}\n",
        "    return {k: {\"mean\": np.mean(val), \"std\": np.std(val)} for k, val in losses.items()}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ed991ca",
      "metadata": {},
      "source": [
        "# First model: MLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "e9b031b2",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sample_id</th>\n",
              "      <th>subject_id</th>\n",
              "      <th>session</th>\n",
              "      <th>run</th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>scanner</th>\n",
              "      <th>site</th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>dataset_name</th>\n",
              "      <th>...</th>\n",
              "      <th>rh_precuneus</th>\n",
              "      <th>rh_rostralanteriorcingulate</th>\n",
              "      <th>rh_rostralmiddlefrontal</th>\n",
              "      <th>rh_superiorfrontal</th>\n",
              "      <th>rh_superiorparietal</th>\n",
              "      <th>rh_superiortemporal</th>\n",
              "      <th>rh_supramarginal</th>\n",
              "      <th>rh_transversetemporal</th>\n",
              "      <th>age_bin</th>\n",
              "      <th>stratify_key</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>IXI002_1_1</td>\n",
              "      <td>IXI002</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>35.80</td>\n",
              "      <td>Female</td>\n",
              "      <td>Philips-1.5T</td>\n",
              "      <td>Guy’s-Hospital</td>\n",
              "      <td>Healthy</td>\n",
              "      <td>IXI</td>\n",
              "      <td>...</td>\n",
              "      <td>2.474847</td>\n",
              "      <td>2.899147</td>\n",
              "      <td>2.635482</td>\n",
              "      <td>3.117611</td>\n",
              "      <td>2.317504</td>\n",
              "      <td>3.213092</td>\n",
              "      <td>2.725745</td>\n",
              "      <td>2.460538</td>\n",
              "      <td>2</td>\n",
              "      <td>2_Female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>IXI012_1_1</td>\n",
              "      <td>IXI012</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>38.78</td>\n",
              "      <td>Male</td>\n",
              "      <td>Philips-3.0T</td>\n",
              "      <td>Hammersmith-Hospital</td>\n",
              "      <td>Healthy</td>\n",
              "      <td>IXI</td>\n",
              "      <td>...</td>\n",
              "      <td>2.131758</td>\n",
              "      <td>2.652905</td>\n",
              "      <td>2.352631</td>\n",
              "      <td>2.635217</td>\n",
              "      <td>2.109884</td>\n",
              "      <td>2.871431</td>\n",
              "      <td>2.485718</td>\n",
              "      <td>2.019534</td>\n",
              "      <td>2</td>\n",
              "      <td>2_Male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>IXI013_1_1</td>\n",
              "      <td>IXI013</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>46.71</td>\n",
              "      <td>Male</td>\n",
              "      <td>Philips-3.0T</td>\n",
              "      <td>Hammersmith-Hospital</td>\n",
              "      <td>Healthy</td>\n",
              "      <td>IXI</td>\n",
              "      <td>...</td>\n",
              "      <td>1.949073</td>\n",
              "      <td>2.655105</td>\n",
              "      <td>2.347103</td>\n",
              "      <td>2.558824</td>\n",
              "      <td>2.037381</td>\n",
              "      <td>2.887120</td>\n",
              "      <td>2.578263</td>\n",
              "      <td>1.791700</td>\n",
              "      <td>4</td>\n",
              "      <td>4_Male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>IXI014_1_1</td>\n",
              "      <td>IXI014</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>34.24</td>\n",
              "      <td>Female</td>\n",
              "      <td>Philips-3.0T</td>\n",
              "      <td>Hammersmith-Hospital</td>\n",
              "      <td>Healthy</td>\n",
              "      <td>IXI</td>\n",
              "      <td>...</td>\n",
              "      <td>2.035774</td>\n",
              "      <td>2.726204</td>\n",
              "      <td>2.491766</td>\n",
              "      <td>2.670686</td>\n",
              "      <td>2.029425</td>\n",
              "      <td>2.860698</td>\n",
              "      <td>2.461032</td>\n",
              "      <td>1.714474</td>\n",
              "      <td>2</td>\n",
              "      <td>2_Female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>IXI015_1_1</td>\n",
              "      <td>IXI015</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>24.28</td>\n",
              "      <td>Male</td>\n",
              "      <td>Philips-3.0T</td>\n",
              "      <td>Hammersmith-Hospital</td>\n",
              "      <td>Healthy</td>\n",
              "      <td>IXI</td>\n",
              "      <td>...</td>\n",
              "      <td>2.267934</td>\n",
              "      <td>2.859262</td>\n",
              "      <td>2.545136</td>\n",
              "      <td>2.780078</td>\n",
              "      <td>2.166804</td>\n",
              "      <td>2.979659</td>\n",
              "      <td>2.727619</td>\n",
              "      <td>2.119733</td>\n",
              "      <td>0</td>\n",
              "      <td>0_Male</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 75 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    sample_id subject_id  session  run    age     sex       scanner  \\\n",
              "0  IXI002_1_1     IXI002        1    1  35.80  Female  Philips-1.5T   \n",
              "1  IXI012_1_1     IXI012        1    1  38.78    Male  Philips-3.0T   \n",
              "2  IXI013_1_1     IXI013        1    1  46.71    Male  Philips-3.0T   \n",
              "3  IXI014_1_1     IXI014        1    1  34.24  Female  Philips-3.0T   \n",
              "4  IXI015_1_1     IXI015        1    1  24.28    Male  Philips-3.0T   \n",
              "\n",
              "                   site diagnosis dataset_name  ... rh_precuneus  \\\n",
              "0        Guy’s-Hospital   Healthy          IXI  ...     2.474847   \n",
              "1  Hammersmith-Hospital   Healthy          IXI  ...     2.131758   \n",
              "2  Hammersmith-Hospital   Healthy          IXI  ...     1.949073   \n",
              "3  Hammersmith-Hospital   Healthy          IXI  ...     2.035774   \n",
              "4  Hammersmith-Hospital   Healthy          IXI  ...     2.267934   \n",
              "\n",
              "   rh_rostralanteriorcingulate  rh_rostralmiddlefrontal  rh_superiorfrontal  \\\n",
              "0                     2.899147                 2.635482            3.117611   \n",
              "1                     2.652905                 2.352631            2.635217   \n",
              "2                     2.655105                 2.347103            2.558824   \n",
              "3                     2.726204                 2.491766            2.670686   \n",
              "4                     2.859262                 2.545136            2.780078   \n",
              "\n",
              "   rh_superiorparietal  rh_superiortemporal  rh_supramarginal  \\\n",
              "0             2.317504             3.213092          2.725745   \n",
              "1             2.109884             2.871431          2.485718   \n",
              "2             2.037381             2.887120          2.578263   \n",
              "3             2.029425             2.860698          2.461032   \n",
              "4             2.166804             2.979659          2.727619   \n",
              "\n",
              "   rh_transversetemporal  age_bin  stratify_key  \n",
              "0               2.460538        2      2_Female  \n",
              "1               2.019534        2        2_Male  \n",
              "2               1.791700        4        4_Male  \n",
              "3               1.714474        2      2_Female  \n",
              "4               2.119733        0        0_Male  \n",
              "\n",
              "[5 rows x 75 columns]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Dataset (from regression lesson)\n",
        "\n",
        "# Let's extract the per thickness matrix\n",
        "def make_thickness_matrix(df,\n",
        "                          sample_id_cols=['subject_id', 'session', 'run'],\n",
        "                          metadata_cols=['age', 'sex', 'scanner', 'site', 'diagnosis', 'dataset_name', 'registered_mni'],\n",
        "                          value_col='mean_thickness_weighted',\n",
        "                          hemi_col='hemi',\n",
        "                          region_col='region',\n",
        "                          aggfunc='mean'):\n",
        "    df = df.copy()\n",
        "    df['sample_id'] = df[sample_id_cols].astype(str).agg('_'.join, axis=1)\n",
        "\n",
        "    # pivoting\n",
        "    index_cols = ['sample_id'] + list(sample_id_cols) + list(metadata_cols)\n",
        "    pivot = df.pivot_table(\n",
        "        index=index_cols,\n",
        "        columns=[hemi_col, region_col],\n",
        "        values=value_col,\n",
        "        aggfunc=aggfunc  # if duplicates exist (e.g., multiple entries), aggregate\n",
        "    )\n",
        "\n",
        "    pivot.columns = [f\"{hemi}_{region}\" for hemi, region in sorted(pivot.columns)]\n",
        "    wide_df = pivot.reset_index()\n",
        "\n",
        "    return wide_df\n",
        "\n",
        "thickness_df = pd.read_csv(\"../data/IXI/thickness.csv\")\n",
        "# Merge the matrix\n",
        "merged = thickness_df.merge(masterfile, on='subject_id', how='inner')\n",
        "merged['age'] = pd.to_numeric(merged['age'], errors='coerce')\n",
        "merged['mean_thickness_weighted'] = pd.to_numeric(merged['mean_thickness_weighted'], errors='coerce')\n",
        "merged['mean_thickness_simple'] = pd.to_numeric(merged['mean_thickness_simple'], errors='coerce')\n",
        "merged = merged.dropna(subset=['age', 'sex', 'mean_thickness_weighted', 'mean_thickness_simple'])\n",
        "# Filter the matrxi\n",
        "merged_filtered = merged[~((merged[\"region\"] == 'temporalpole') & (merged[\"hemi\"] == \"rh\") | (merged[\"region\"] == \"unknown\"))]\n",
        "# obtain the df matrix\n",
        "proper_thickness_matrix_df = make_thickness_matrix(\n",
        "    df=merged_filtered,\n",
        "    value_col='mean_thickness_weighted'\n",
        ")\n",
        "\n",
        "test_set = proper_thickness_matrix_df[proper_thickness_matrix_df[\"scanner\"] == \"GE-1.5T\"]\n",
        "train_set = proper_thickness_matrix_df[proper_thickness_matrix_df[\"scanner\"] != \"GE-1.5T\"]\n",
        "\n",
        "internal_df = train_set.copy()\n",
        "internal_df[\"age_bin\"] = pd.cut(train_set[\"age\"], bins=10, labels=False, include_lowest=True)\n",
        "internal_df[\"stratify_key\"] = internal_df[\"age_bin\"].astype(str) + \"_\" + internal_df[\"sex\"].astype(str)\n",
        "internal_df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "dde9c97a",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/afrotscher/miniconda3/envs/myenv/lib/python3.10/site-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=3.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# This time I do SKF\n",
        "skf = StratifiedKFold(n_splits = 3, shuffle = False)\n",
        "folds = [(train_fold, val_fold) for train_fold, val_fold in skf.split(np.arange(len(internal_df)), internal_df[\"stratify_key\"].values)]\n",
        "len(folds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "e963e1af",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'cort': tensor([2.7676, 2.8286, 2.0199, 2.7128, 2.8419, 2.4874, 3.1024, 3.1808, 2.4890,\n",
              "         2.1395, 2.6867, 1.9539, 2.5086, 2.9185, 2.6467, 2.8679, 2.6350, 2.8145,\n",
              "         2.8272, 1.5510, 2.2510, 2.4814, 2.7461, 2.5553, 2.9170, 2.8129, 3.0472,\n",
              "         2.3132, 3.1159, 2.7137, 2.6597, 2.6050, 2.9449, 1.9366, 2.8172, 2.8733,\n",
              "         2.6456, 3.2003, 3.2687, 2.4619, 2.3114, 2.7239, 1.8627, 2.5346, 2.9950,\n",
              "         2.6629, 2.7215, 2.7494, 2.9277, 2.7340, 1.5249, 2.0854, 2.5268, 2.6698,\n",
              "         2.4748, 2.8991, 2.6355, 3.1176, 2.3175, 3.2131, 2.7257, 2.4605]),\n",
              " 'age': tensor(35.8000)}"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Dataset\n",
        "class CorthicalThicknessDataset(Dataset):\n",
        "    def __init__(self,\n",
        "                 metadata_df: pd.DataFrame,\n",
        "                 features: List[str],\n",
        "                 transform = None,\n",
        "                 age_transforms = None):\n",
        "        self.df = metadata_df\n",
        "        self.transform = transform\n",
        "        self.age_transforms = age_transforms\n",
        "        self.features = features\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row: pd.Series = self.df.iloc[idx]\n",
        "        age = float(row[\"age\"])\n",
        "        features = row[self.features].values.astype(np.float32)\n",
        "        if self.transform:\n",
        "            features = self.transform(features)\n",
        "        if self.age_transforms:\n",
        "            age = self.age_transforms(age)\n",
        "        return {\n",
        "            \"cort\": features if th.is_tensor(features) else th.as_tensor(features),\n",
        "            \"age\": (age if th.is_tensor(age) else th.as_tensor(age)).type(dtype=th.float32),\n",
        "        }\n",
        "\n",
        "labels_features = [c for c in train_set.columns if \"lh\" in c or \"rh\" in c] \n",
        "cds = CorthicalThicknessDataset(metadata_df=train_set, \n",
        "                                features=labels_features)\n",
        "cds[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "eed38d1d",
      "metadata": {},
      "outputs": [],
      "source": [
        "def apply_scaler(df, scaler, num_cols):\n",
        "    df_scaled = df.copy()\n",
        "    df_scaled[num_cols] = scaler.transform(df[num_cols])\n",
        "    return df_scaled\n",
        "\n",
        "def get_loaders_thk(train_set,\n",
        "                    val_set,\n",
        "                    features,\n",
        "                    train_transforms=None,\n",
        "                    val_transforms=None,\n",
        "                    age_transforms=None,\n",
        "                    batch_size=16):\n",
        "\n",
        "    # Scale the corthical thicknesses \n",
        "    scaler = StandardScaler()\n",
        "    scaler.fit(train_set[features])\n",
        "\n",
        "    train_scaled = apply_scaler(train_set, scaler, features)\n",
        "    val_scaled   = apply_scaler(val_set, scaler, features)\n",
        "\n",
        "    ds_tr = CorthicalThicknessDataset(\n",
        "        train_scaled,\n",
        "        features=features,\n",
        "        transform=train_transforms,\n",
        "        age_transforms=age_transforms\n",
        "    )\n",
        "\n",
        "    train_dl = DataLoader(ds_tr, batch_size=batch_size,\n",
        "                            shuffle=True,\n",
        "                            num_workers=6,\n",
        "                            pin_memory=True,\n",
        "                            persistent_workers=True,\n",
        "                            prefetch_factor=2)\n",
        "    \n",
        "    ds_val = CorthicalThicknessDataset(\n",
        "        val_scaled,\n",
        "        features=features,\n",
        "        transform=val_transforms,\n",
        "        age_transforms=age_transforms\n",
        "    )\n",
        "    val_dl = DataLoader(ds_val, batch_size=batch_size,\n",
        "                            num_workers=2,\n",
        "                            pin_memory=False,\n",
        "                            persistent_workers=True,\n",
        "                            prefetch_factor=None)\n",
        "                            # persistent_workers=True,\n",
        "                            # prefetch_factor=2)\n",
        "\n",
        "    return train_dl, val_dl, scaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "746698d8",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'cort': tensor([[-1.4895e+00, -8.6988e-01, -1.3153e+00,  2.4317e-01, -2.5327e-01,\n",
              "          -1.5475e+00, -1.8220e+00, -2.6167e+00,  1.3202e-01, -2.5823e-01,\n",
              "          -1.6089e+00, -4.5825e-01, -1.6113e+00, -2.2403e+00, -5.0683e-01,\n",
              "          -1.2371e+00, -1.6097e+00, -2.0359e+00, -2.5105e+00, -8.9627e-01,\n",
              "          -2.7559e+00, -4.5902e-01, -2.6403e+00, -9.9167e-01, -1.1777e+00,\n",
              "          -9.9487e-01, -1.5530e+00, -1.8158e-01, -2.0718e+00, -1.3942e+00,\n",
              "           5.2000e-01, -6.9565e-01, -1.5666e+00, -9.2259e-01,  6.8357e-01,\n",
              "          -3.8094e-01, -8.4504e-01, -5.6212e-01, -2.7066e+00, -4.8013e-01,\n",
              "          -1.3899e+00, -1.4115e+00, -9.8437e-01, -5.0582e-01, -8.6327e-01,\n",
              "          -9.2207e-01, -4.8917e-01, -1.4247e+00, -1.7547e+00, -2.1948e+00,\n",
              "          -3.3192e-01, -2.0167e+00, -1.1864e-01, -2.8528e+00, -1.0594e+00,\n",
              "          -1.3328e+00, -1.2463e+00, -1.6035e+00, -1.0547e+00, -1.4242e+00,\n",
              "          -1.8224e+00,  6.6554e-01],\n",
              "         [-6.3447e-01,  6.9745e-01,  6.0751e-01,  9.3606e-02,  6.9549e-01,\n",
              "           1.8704e-01,  1.2994e+00, -7.4783e-01,  6.1750e-02,  1.0251e+00,\n",
              "           3.1521e-01,  2.9152e-01,  1.6057e+00,  5.2518e-01,  1.5928e-01,\n",
              "           7.0107e-01, -7.3189e-01,  9.9607e-01,  4.8451e-01,  2.3314e+00,\n",
              "           8.6641e-01, -2.0283e-01,  2.0495e-01,  7.5821e-01, -7.0432e-01,\n",
              "          -1.1415e-01,  7.3183e-01,  9.2732e-01,  5.7448e-01,  4.2061e-01,\n",
              "           9.2471e-02, -7.0727e-02, -9.7637e-01,  1.1714e+00, -1.5420e-01,\n",
              "           5.3872e-01,  4.1215e-01,  1.2943e+00, -1.2489e-01,  4.8565e-01,\n",
              "           4.5293e-01,  2.0608e-01,  1.2216e-01,  3.1881e-01,  5.6463e-02,\n",
              "           2.2449e-01,  1.1381e+00, -1.6911e-01, -4.3328e-01,  4.5424e-01,\n",
              "           1.9897e-02,  9.7526e-01,  3.5173e-01,  1.8086e-01,  8.2469e-01,\n",
              "          -1.8578e-01,  6.6387e-02,  2.9398e-01,  1.0918e+00,  6.3118e-01,\n",
              "           7.6181e-01,  1.4916e+00],\n",
              "         [ 7.2504e-01,  8.7042e-01,  4.6834e-01,  1.0070e+00, -8.8100e-02,\n",
              "          -1.2194e-01,  2.8134e-01,  2.0810e+00,  2.4946e+00, -4.2988e-01,\n",
              "           2.2295e-01,  4.4907e-01,  1.8570e-01,  2.8165e-01,  6.4667e-01,\n",
              "           1.6271e-01,  1.5094e+00,  9.7403e-01,  1.3682e+00,  1.0138e+00,\n",
              "           1.2827e+00,  1.1033e+00,  9.8128e-01,  1.2674e+00,  1.6901e+00,\n",
              "           8.5984e-01,  1.0840e+00,  6.0928e-01, -2.4608e-02,  9.0014e-01,\n",
              "           8.7961e-01,  1.3812e+00,  1.6440e+00,  1.2678e+00, -1.4306e+00,\n",
              "          -1.5475e-01,  1.2002e-01, -1.0111e-01,  1.2682e+00,  2.0123e+00,\n",
              "          -2.9197e-01,  6.9163e-02,  8.3577e-01,  2.5706e-01,  1.8784e-01,\n",
              "           6.7546e-01,  5.2090e-02,  1.8722e+00,  1.4604e+00,  5.2123e-01,\n",
              "           1.0066e+00,  6.1250e-01,  1.5372e+00,  8.7307e-01,  6.3198e-01,\n",
              "           1.3213e+00,  8.4746e-01,  1.3515e+00,  4.1141e-01,  2.9310e-01,\n",
              "           1.0162e+00,  4.7529e-01],\n",
              "         [-1.8708e-01, -8.0953e-01, -5.9862e-01,  5.8163e-01, -6.5991e-01,\n",
              "           8.8969e-01,  5.5853e-01,  7.7936e-01, -5.4155e-01,  3.8326e-02,\n",
              "          -1.4495e-01, -1.4735e+00,  7.7988e-02,  7.2860e-01, -1.2597e+00,\n",
              "          -5.5081e-01, -3.9448e-01,  2.5664e-01, -4.9561e-01, -8.4207e-01,\n",
              "          -9.6125e-01, -1.1528e+00, -4.9819e-01, -1.7633e-01, -8.5691e-01,\n",
              "           8.8699e-02,  5.5481e-01,  2.3137e-02, -3.3306e-01,  3.8818e-01,\n",
              "           7.3180e-02, -6.5856e-01, -4.4728e-01, -3.8895e-01,  2.2655e-01,\n",
              "          -5.9220e-01, -4.6066e-01, -3.6585e-01,  3.1361e-02,  4.5904e-01,\n",
              "          -7.5744e-01,  4.4457e-01, -1.0147e+00, -8.2217e-01, -4.4070e-01,\n",
              "          -8.7227e-01, -1.6793e+00, -6.1842e-01,  1.0787e+00, -8.7558e-02,\n",
              "          -1.4154e+00, -1.3563e+00,  1.4379e-02, -9.0568e-01,  1.5356e-01,\n",
              "          -4.0054e-01, -1.9244e-02, -1.9260e-01,  5.5344e-02,  3.2950e-01,\n",
              "          -5.6962e-01, -6.4396e-02],\n",
              "         [-1.3010e+00, -1.0148e+00,  5.4566e-01, -2.6451e+00, -5.2606e-01,\n",
              "          -9.2417e-01, -1.4111e+00, -1.1420e+00,  1.7266e-01, -2.3646e-02,\n",
              "          -7.9927e-01, -1.7577e-01, -1.3790e+00, -8.1262e-01, -1.3645e+00,\n",
              "          -6.1749e-01, -7.0235e-01, -4.1708e-01, -1.3532e+00,  3.5043e-01,\n",
              "          -1.9264e-03,  1.1453e-01, -1.1681e+00, -5.1136e-01, -2.3573e+00,\n",
              "          -6.8634e-01, -1.0325e+00, -2.3556e-01, -9.3076e-01, -8.5256e-01,\n",
              "           1.3709e+00, -2.0101e-01, -4.4842e-01, -6.1157e-01,  1.3783e-01,\n",
              "          -6.7173e-01, -1.0921e+00, -1.8258e+00, -7.5993e-01, -3.6530e-01,\n",
              "          -5.7514e-01, -1.5156e+00, -5.4548e-01, -7.6262e-01, -4.0682e-01,\n",
              "          -1.1014e+00, -4.4323e-01, -9.9458e-01, -1.3970e+00, -1.9475e+00,\n",
              "          -1.1965e-02, -4.6888e-02, -1.5529e+00, -8.6312e-01, -1.1472e+00,\n",
              "          -1.5112e+00, -1.3877e+00, -1.1756e+00, -1.7921e-01, -7.6126e-01,\n",
              "          -8.4069e-01,  1.9729e-01],\n",
              "         [-4.7649e-01, -3.7413e-01, -9.3430e-01, -4.2411e-01, -4.5545e-01,\n",
              "          -7.8906e-02, -7.7078e-01, -1.0092e+00,  1.5071e+00,  8.3980e-01,\n",
              "          -6.6819e-01, -3.9280e-01,  1.9531e-01, -8.9852e-02,  7.8545e-02,\n",
              "          -1.3192e+00,  4.1486e-01, -1.2926e+00, -4.4009e-01,  5.8569e-02,\n",
              "           3.3827e-02,  3.2406e-01, -6.6451e-01,  3.0715e-01, -1.3453e+00,\n",
              "          -7.0508e-01, -7.2559e-01,  5.9662e-02, -8.3256e-01,  1.0095e+00,\n",
              "          -2.0001e-01, -1.0212e+00, -7.9875e-02, -6.6858e-01,  3.8107e-01,\n",
              "          -1.1186e+00, -8.2791e-02, -3.9717e-01, -1.5648e+00,  7.5039e-01,\n",
              "           4.0139e-01,  2.6246e-02, -2.9679e-02, -6.9503e-01,  3.6028e-01,\n",
              "           2.1271e-01, -1.8626e+00, -8.7962e-01, -1.9503e+00, -9.0060e-01,\n",
              "           4.5560e-01,  3.1987e-01, -3.3427e-01, -7.1374e-01,  4.0003e-01,\n",
              "          -2.7852e-01, -7.1085e-01, -6.4253e-01,  3.2614e-01, -7.5853e-01,\n",
              "          -1.1305e-01, -4.2970e-01],\n",
              "         [ 1.9892e+00,  1.1467e+00, -6.2656e-01, -1.5426e+00,  3.9180e-01,\n",
              "           4.3764e-01, -5.4370e-01,  9.3509e-01,  2.7585e-01, -9.0918e-01,\n",
              "           5.4638e-01, -7.7377e-01,  8.3538e-01,  1.8260e-01,  1.0620e+00,\n",
              "           1.2393e+00,  9.2249e-01, -5.4723e-02,  1.4475e+00, -1.0472e-01,\n",
              "           6.4430e-01, -4.7255e-01,  1.2081e+00,  4.1016e-01,  1.2802e+00,\n",
              "           9.4901e-01,  1.5036e+00, -5.9546e-01,  1.5572e-01,  2.4667e-01,\n",
              "           5.0795e-01,  2.3371e+00,  1.4084e+00,  1.7526e-01, -8.9869e-01,\n",
              "           3.7199e-02,  1.1664e+00,  6.4149e-03,  1.0097e-01,  6.2603e-01,\n",
              "          -1.9998e-01,  4.7817e-01, -2.5100e-01,  2.2289e+00,  7.8845e-01,\n",
              "           8.4380e-01,  3.1561e-01,  1.1915e+00,  3.5693e-01,  2.3070e+00,\n",
              "          -7.4097e-01,  1.6615e-01,  2.3410e-01,  8.8321e-01, -1.2882e-02,\n",
              "           1.5112e+00,  1.5587e+00,  1.4334e+00,  3.5655e-01,  1.7605e-01,\n",
              "           1.0681e+00,  8.0467e-01],\n",
              "         [ 8.8247e-01,  1.7071e-01,  2.9943e-02, -3.1284e-01, -1.4096e+00,\n",
              "          -3.4200e-01, -7.0826e-01,  1.9560e-01,  2.2797e-01, -8.3130e-01,\n",
              "          -3.5489e-01, -7.9984e-01, -5.0467e-01, -6.0408e-01,  6.5120e-02,\n",
              "           3.6850e-01,  8.2939e-01, -2.6515e-01,  1.2059e-01,  8.4313e-01,\n",
              "           6.9543e-02, -1.3128e-01,  6.3415e-01, -7.6258e-01,  5.1340e-01,\n",
              "          -1.3661e-01,  2.8265e-02, -3.5786e-01,  5.7843e-01, -2.0487e-01,\n",
              "          -2.0935e+00, -6.0540e-02,  2.8063e-01, -4.6913e-01, -8.6889e-01,\n",
              "          -1.0901e+00, -1.8081e-01, -1.3358e+00, -1.4264e+00,  1.0699e+00,\n",
              "          -4.1647e-01, -3.3138e-01,  2.7726e-01,  3.0860e-01,  2.6603e-01,\n",
              "          -4.1200e-01, -1.2347e+00,  2.9463e-01,  1.9394e-01,  1.6903e-01,\n",
              "           7.9799e-01, -8.0862e-01,  3.1698e-01,  5.3351e-01,  3.8609e-01,\n",
              "           7.0184e-01, -8.7911e-01,  4.3539e-01, -9.6802e-01,  6.3984e-01,\n",
              "           1.5256e-01, -2.0502e+00],\n",
              "         [-1.2601e+00, -9.6728e-01, -7.0712e-01,  4.0634e-01, -9.3148e-01,\n",
              "          -7.4993e-01, -5.5972e-01, -1.5356e+00,  4.7255e-01, -8.7565e-01,\n",
              "          -1.1589e+00, -1.2528e+00, -1.2586e+00, -4.3707e-01, -6.0434e-01,\n",
              "          -1.3622e-01, -5.2504e-01, -1.6226e+00, -1.0424e+00, -1.2472e+00,\n",
              "          -5.5459e-01, -1.1580e+00, -6.0963e-01, -1.9287e+00, -2.4618e+00,\n",
              "          -1.2853e+00, -1.8469e+00, -1.0249e+00, -1.0329e+00, -9.0093e-01,\n",
              "           1.0840e-01,  5.3091e-01, -1.3225e+00, -1.1417e+00, -1.5605e-01,\n",
              "          -1.1185e+00, -9.3894e-01, -1.2200e+00, -1.1780e+00, -2.7261e-01,\n",
              "          -6.6728e-01, -1.4158e+00, -1.2832e+00, -1.0227e+00, -1.1848e+00,\n",
              "           1.2407e-01, -1.3929e+00, -1.1232e+00, -6.3159e-01, -1.6546e-01,\n",
              "          -4.8028e-02,  3.9974e-01, -2.7723e-02, -1.3903e+00, -1.3790e+00,\n",
              "          -1.6125e+00, -1.6455e+00, -1.6310e+00, -4.9443e-01, -1.8016e+00,\n",
              "          -6.2886e-01, -1.0534e+00],\n",
              "         [-6.2524e-01, -1.7631e+00, -1.9907e+00, -1.9888e+00, -1.2964e+00,\n",
              "          -1.6414e+00, -1.4808e+00, -2.0340e+00, -1.1443e+00, -2.3591e+00,\n",
              "          -1.3527e+00, -6.9204e-01, -1.8403e+00, -1.0041e+00, -2.2391e+00,\n",
              "           6.3755e-01, -1.0335e+00, -1.3765e+00, -1.8087e+00, -2.3129e-02,\n",
              "          -1.5744e+00, -1.5991e+00, -2.1925e+00, -1.6799e+00, -3.6915e-02,\n",
              "          -2.8106e-01, -6.0082e-01, -2.3435e+00, -4.2830e-01, -1.9517e+00,\n",
              "          -5.4628e-01, -3.3060e-01, -1.9156e+00, -9.8383e-01, -1.5402e+00,\n",
              "          -8.0750e-01, -1.6437e+00, -1.3129e+00, -1.0646e+00, -1.8365e+00,\n",
              "          -2.3803e+00, -1.3682e+00, -1.3104e+00, -9.4277e-01, -6.3751e-01,\n",
              "          -1.6836e+00, -2.5369e-01, -5.1064e-01, -4.4894e-01, -6.1232e-01,\n",
              "          -1.6409e+00, -9.0084e-01, -1.2763e+00, -1.8108e+00, -1.2196e+00,\n",
              "          -7.9562e-01, -1.1760e-01, -1.0164e+00, -2.0887e+00, -5.1359e-01,\n",
              "          -8.2114e-01, -8.5837e-01],\n",
              "         [ 4.0779e-01,  1.1015e+00, -5.5516e-01, -6.6952e-01, -6.1163e-01,\n",
              "          -1.4046e-01,  3.4460e-02,  6.8934e-01,  5.2129e-02, -1.2747e+00,\n",
              "           5.5645e-01, -4.5085e-01,  8.5397e-01, -9.4245e-01,  1.2601e-01,\n",
              "          -1.2605e+00,  1.5586e+00,  3.3800e-01,  4.5559e-01, -3.7592e-01,\n",
              "          -6.3097e-01,  5.4059e-02, -4.6284e-01, -5.2850e-01,  3.3939e-01,\n",
              "           6.1641e-01,  1.0636e+00, -6.4026e-01, -1.1425e+00,  3.4184e-01,\n",
              "          -1.5985e+00,  4.7511e-01,  1.2959e-01, -5.3534e-01, -9.8539e-01,\n",
              "          -4.7872e-01,  5.1591e-01, -1.6109e-01, -1.9106e-01, -1.1724e+00,\n",
              "          -1.9573e+00,  1.5424e+00, -7.4365e-01,  1.3409e-01,  1.7603e-01,\n",
              "          -5.3252e-01, -1.1511e+00,  7.6921e-01,  1.9740e-01,  5.9386e-01,\n",
              "          -1.0734e+00, -2.7718e-01,  3.4070e-01, -2.0974e-01, -4.0982e-01,\n",
              "          -2.2168e-01,  5.0235e-01,  8.5657e-01, -4.4813e-01, -2.6878e-01,\n",
              "          -7.8856e-02, -1.2683e+00],\n",
              "         [ 1.3502e+00,  1.4843e+00,  1.4680e+00, -9.7608e-01,  1.7457e+00,\n",
              "           1.5623e+00,  1.0429e+00,  1.7272e+00,  1.2219e+00,  5.2404e-01,\n",
              "           9.8965e-01,  8.2079e-01, -1.4070e-01,  4.8726e-01,  4.8585e-01,\n",
              "           8.3522e-01,  8.3706e-01,  9.2292e-01,  1.3806e+00,  1.6847e+00,\n",
              "           2.0777e+00,  4.8321e-01,  1.1886e+00,  1.4559e+00,  1.1019e+00,\n",
              "           7.9944e-01,  1.8415e+00,  2.0213e+00,  1.0513e+00,  1.5056e+00,\n",
              "           9.5327e-01, -4.2140e-01,  1.5097e+00,  9.4198e-01,  1.4828e-01,\n",
              "           1.1075e+00,  1.6680e+00,  8.6498e-01,  4.5516e-01,  9.4067e-01,\n",
              "           1.4329e+00,  1.1254e+00, -3.4410e-01,  1.0984e+00,  4.0447e-01,\n",
              "          -3.1169e-02, -7.3342e-01,  9.4917e-01,  8.2767e-01,  1.3788e+00,\n",
              "          -6.1905e-01,  1.7690e+00, -2.4249e-01,  6.3832e-01,  1.9940e+00,\n",
              "           7.6662e-01,  1.9005e+00,  1.7246e+00,  1.9619e+00,  1.1294e+00,\n",
              "           1.9562e+00, -4.6026e-01],\n",
              "         [ 1.3812e+00,  1.3134e+00,  6.8030e-01,  6.8937e-01,  1.0471e+00,\n",
              "           7.3930e-01,  1.9029e+00,  7.0680e-01,  1.2937e+00,  1.2508e+00,\n",
              "           7.6435e-01,  1.4330e+00,  9.6436e-01,  1.6516e+00,  1.2366e+00,\n",
              "          -1.9661e-01,  2.0567e-01,  1.0584e+00,  1.4802e+00, -8.2795e-01,\n",
              "          -3.4126e-01,  1.6789e+00,  1.4061e+00,  1.2579e+00,  5.6546e-01,\n",
              "           1.5950e+00,  2.0300e+00,  1.2795e+00,  1.4736e+00,  9.9281e-01,\n",
              "           2.0576e+00,  7.4240e-01,  1.0629e+00,  7.4447e-01,  4.9839e-02,\n",
              "           8.8920e-01,  1.0751e+00,  9.6751e-01, -1.4122e-02,  1.1722e+00,\n",
              "           9.1130e-01,  4.3885e-01,  1.0243e+00,  6.7343e-01,  1.3729e+00,\n",
              "           1.5205e+00, -2.0304e-01,  7.5354e-01,  5.7645e-01,  7.0877e-01,\n",
              "          -8.1057e-01,  6.2019e-01,  1.3225e+00,  1.1597e+00,  2.2893e-01,\n",
              "           1.0054e-01,  7.2186e-01,  1.6492e+00,  6.5846e-01,  1.5053e+00,\n",
              "           1.0025e+00,  6.2364e-01],\n",
              "         [-2.7672e-01,  6.9637e-02,  1.1561e+00,  1.5222e+00,  4.4965e-01,\n",
              "           5.3711e-01,  1.3734e+00, -4.0461e-02,  4.9369e-01,  1.4818e+00,\n",
              "           3.2017e-01,  1.8340e+00,  2.8849e-01,  1.3993e+00,  4.6234e-01,\n",
              "           9.7345e-01, -1.0910e-01,  1.9234e-02, -8.2776e-01,  1.9401e+00,\n",
              "           7.0446e-01, -6.0820e-01,  6.2945e-01,  5.7759e-02, -7.8896e-02,\n",
              "          -2.8497e-02,  1.7382e-01,  6.6781e-01,  1.5433e+00, -5.0367e-02,\n",
              "           1.6067e+00, -1.4501e+00,  3.0441e-01,  2.8011e+00,  2.0397e+00,\n",
              "           1.6663e+00,  1.7616e+00,  3.3161e-01,  4.6295e-01, -9.3338e-01,\n",
              "           1.9181e+00,  9.5800e-01,  1.1370e+00,  1.9870e-01,  1.0336e+00,\n",
              "          -1.4996e-01,  7.4500e-01,  1.5542e-01,  6.1877e-01, -1.0154e-01,\n",
              "           2.2017e+00,  2.2098e-01,  6.0709e-01,  7.3160e-01,  6.8448e-01,\n",
              "          -6.8048e-01, -2.6650e-01,  2.2159e-01,  6.8180e-01,  1.4904e+00,\n",
              "          -1.7455e-01,  9.6147e-01],\n",
              "         [-3.1729e-01,  9.9459e-01,  1.4583e+00,  8.2062e-01,  8.3515e-01,\n",
              "           9.1387e-01,  2.8391e-01, -7.2672e-01,  5.4326e-01,  5.9736e-01,\n",
              "           4.5356e-01,  2.5169e+00,  8.9435e-01,  6.3619e-01,  1.4513e+00,\n",
              "           9.7310e-01, -5.9307e-01,  9.4147e-01, -2.1346e-02,  2.5242e+00,\n",
              "           1.5361e-01,  2.6697e-01, -4.1376e-01,  6.6870e-01,  7.0386e-01,\n",
              "           6.5260e-01,  5.1935e-02,  1.2966e+00,  4.7711e-01,  7.5216e-01,\n",
              "           7.4402e-01,  1.1967e+00,  8.2425e-01,  2.2966e+00,  1.6551e+00,\n",
              "           3.3857e-01,  1.7820e-01,  7.6061e-01, -9.6018e-01,  1.8129e+00,\n",
              "          -1.6104e-02,  4.4952e-01,  1.0450e+00,  1.0346e+00,  9.7725e-01,\n",
              "          -6.3335e-01, -4.8200e-01,  7.0162e-01,  3.3589e-01, -6.9813e-01,\n",
              "          -4.1210e-02,  8.6776e-02,  1.4259e+00,  5.5548e-01,  1.1939e+00,\n",
              "           1.8069e-01, -3.4399e-01,  3.0657e-02,  9.1929e-01,  5.0719e-01,\n",
              "           1.7398e-01,  7.3285e-01],\n",
              "         [ 1.2692e+00,  9.3318e-01, -2.7267e-01,  6.0179e-01, -9.6662e-02,\n",
              "           1.0781e+00,  4.4840e-02,  1.3984e+00,  9.7092e-01,  5.8836e-01,\n",
              "          -6.7827e-02, -3.9024e-01, -7.2487e-03,  6.6821e-01,  3.1322e-01,\n",
              "           8.9474e-01,  1.5599e+00,  1.9203e-01,  3.8632e-01,  5.8712e-01,\n",
              "           7.8749e-01,  2.6367e+00,  1.1398e+00,  7.6525e-01,  7.3855e-01,\n",
              "           5.9983e-01,  5.0803e-01,  4.0756e-01,  1.5161e+00,  1.2265e+00,\n",
              "           6.3562e-01,  1.3155e+00,  3.1559e-01, -5.0949e-01,  1.4387e-01,\n",
              "          -5.9245e-01,  1.1502e+00,  1.3182e+00,  6.9698e-01,  7.1348e-01,\n",
              "           1.8333e-01,  5.9617e-01, -1.2836e+00, -2.6877e-01,  5.0346e-01,\n",
              "           9.1813e-02,  7.3186e-01,  4.7596e-01,  1.0511e+00,  3.9185e-01,\n",
              "          -8.6414e-01,  1.1780e+00,  2.2698e+00,  1.1517e+00,  3.3190e-01,\n",
              "           9.0239e-01, -3.1907e-01,  4.8999e-01,  8.9350e-01,  9.8541e-01,\n",
              "           1.1306e+00,  2.6974e-01]]),\n",
              " 'age': tensor([0.2640, 0.1704, 0.0956, 0.2011, 0.2503, 0.2354, 0.0821, 0.1789, 0.2622,\n",
              "         0.1760, 0.1058, 0.1431, 0.0929, 0.2435, 0.2632, 0.2356])}"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dl, val_dl, scaler = get_loaders_thk(\n",
        "    train_set.iloc[folds[0][0]],\n",
        "    train_set.iloc[folds[0][1]],\n",
        "    labels_features,\n",
        "    age_transforms=lambda x: x/255.,\n",
        "    batch_size=16\n",
        ")\n",
        "next(iter(train_dl))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "b1f6e56d",
      "metadata": {},
      "outputs": [],
      "source": [
        "class MLPCort(nn.Module):\n",
        "    def __init__(self, in_dim: int, hidden: List[int], dropout: float = 0.0):\n",
        "        super().__init__()\n",
        "        layers: List[nn.Module] = []\n",
        "        prev = in_dim\n",
        "        for h in hidden:\n",
        "            layers += [\n",
        "                nn.Linear(prev, h),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Dropout(dropout),\n",
        "            ]\n",
        "            prev = h\n",
        "        layers += [nn.Linear(prev, 1)]  # regression output\n",
        "        self.net = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x: th.Tensor) -> th.Tensor:\n",
        "        return self.net(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5f8905d",
      "metadata": {},
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "get_loaders_thk() got an unexpected keyword argument 'train_idx'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[15], line 53\u001b[0m\n\u001b[1;32m     50\u001b[0m results_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(base_results_dir, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexp_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_fold\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_results.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     51\u001b[0m summary_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(base_results_dir, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexp_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_cv_summary.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 53\u001b[0m train_dl, val_dl, _ \u001b[38;5;241m=\u001b[39m \u001b[43mget_loaders_thk\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_idx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_set\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_idx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_set\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mval_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_transforms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_transforms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mage_transforms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m255.\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\n\u001b[1;32m     57\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m network \u001b[38;5;241m=\u001b[39m MLPCort(\n\u001b[1;32m     60\u001b[0m     in_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(labels_features),\n\u001b[1;32m     61\u001b[0m     hidden\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m32\u001b[39m,\u001b[38;5;241m64\u001b[39m,\u001b[38;5;241m16\u001b[39m]\n\u001b[1;32m     62\u001b[0m )\u001b[38;5;241m.\u001b[39mto(device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m     63\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m th\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdamW(network\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m)\n",
            "\u001b[0;31mTypeError\u001b[0m: get_loaders_thk() got an unexpected keyword argument 'train_idx'"
          ]
        }
      ],
      "source": [
        "num_epochs = 50\n",
        "warmup_epochs = 10\n",
        "exp_name = \"CorthicalThickness\"\n",
        "base_ckpt_dir = f\"../checkpoints/{exp_name}\"\n",
        "base_results_dir = f\"../results/{exp_name}\"\n",
        "os.makedirs(base_ckpt_dir, exist_ok=True)\n",
        "os.makedirs(base_results_dir, exist_ok=True)\n",
        "\n",
        "device = th.device(\"cuda\" if th.cuda.is_available() else \"cpu\")\n",
        "delta = 0.10\n",
        "criterion_train = nn.HuberLoss(delta=delta)\n",
        "\n",
        "\n",
        "def build_scheduler(optimizer, train_dl, max_lr=1e-2, base_lr=1e-4, warmup_epochs=60):\n",
        "    base_lrs = [g['lr'] for g in optimizer.param_groups]\n",
        "    factors = [base_lr / b for b in base_lrs]  # -> usually 1.0 if base_lr == optimizer init lr\n",
        "    lambdas = [(lambda f: (lambda _: f))(f) for f in factors]\n",
        "    const = th.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambdas)\n",
        "\n",
        "    total_warm_steps = len(train_dl) * warmup_epochs\n",
        "    oc = th.optim.lr_scheduler.OneCycleLR(\n",
        "        optimizer=optimizer,\n",
        "        max_lr=max_lr,\n",
        "        total_steps=total_warm_steps,\n",
        "        pct_start=0.4,\n",
        "        anneal_strategy=\"cos\",\n",
        "        div_factor=100.0,      # initial_lr = max_lr / div_factor\n",
        "        final_div_factor=max_lr/base_lr,  # final_lr ~ max_lr / 50\n",
        "        cycle_momentum=False\n",
        "    )\n",
        "    # After OneCycle finishes, switch to \"const\" (restores base_lr)\n",
        "    sched = th.optim.lr_scheduler.SequentialLR(\n",
        "        optimizer=optimizer,\n",
        "        schedulers=[oc, const],\n",
        "        milestones=[total_warm_steps]\n",
        "    )\n",
        "    return sched, total_warm_steps\n",
        "\n",
        "def save_fold_summary(all_best_rows, path):\n",
        "    if len(all_best_rows) == 0:\n",
        "        return\n",
        "    df = pd.DataFrame(all_best_rows)\n",
        "    df.to_csv(path, index=False)\n",
        "\n",
        "cv_best_rows = []\n",
        "\n",
        "for i, fold in enumerate(folds):\n",
        "    train_idx, val_idx = fold\n",
        "    ckpt_path = os.path.join(base_ckpt_dir, f\"{exp_name}_fold{i}_best.pth\")\n",
        "    results_path = os.path.join(base_results_dir, f\"{exp_name}_fold{i}_results.csv\")\n",
        "    summary_path = os.path.join(base_results_dir, f\"{exp_name}_cv_summary.csv\")\n",
        "\n",
        "    train_dl, val_dl, _ = get_loaders_thk(\n",
        "        train_set=train_set.iloc[train_idx], val_set=train_set.iloc[val_idx], features=labels_features,\n",
        "        train_transforms=None, val_transforms=None, age_transforms=lambda x: x/255.,\n",
        "        batch_size=32\n",
        "    )\n",
        "\n",
        "    network = MLPCort(\n",
        "        in_dim=len(labels_features),\n",
        "        hidden=[32,64,16],\n",
        "        dropout=0.3\n",
        "    ).to(device=device)\n",
        "    optimizer = th.optim.AdamW(network.parameters(), lr=1e-3)\n",
        "\n",
        "    scheduler, warm_steps = build_scheduler(\n",
        "        optimizer=optimizer,\n",
        "        train_dl=train_dl,\n",
        "        max_lr=1e-2,\n",
        "        base_lr=1e-4,\n",
        "        warmup_epochs=warmup_epochs\n",
        "    )\n",
        "\n",
        "    best_val_mae = np.inf\n",
        "    curr_epoch = -1\n",
        "\n",
        "    if os.path.exists(ckpt_path):\n",
        "        state_dict = th.load(ckpt_path, weights_only=False, map_location=device)\n",
        "        curr_epoch = state_dict[\"epoch\"]\n",
        "        best_val_mae = state_dict[\"best_val_mae\"]\n",
        "        network.load_state_dict(state_dict[\"model_state_dict\"])\n",
        "        optimizer.load_state_dict(state_dict[\"optimizer_state_dict\"])\n",
        "\n",
        "        # Restore scheduler position (step-per-batch scheduler)\n",
        "        scheduler.last_epoch = (curr_epoch + 1) * len(train_dl) - 1\n",
        "\n",
        "        print(f\"[Fold {i}] Reloaded checkpoint from epoch {curr_epoch} (best_val_mae={best_val_mae:.3f})\")\n",
        "\n",
        "    # Resume results table for this fold\n",
        "    if os.path.exists(results_path):\n",
        "        losses = pd.read_csv(results_path)\n",
        "        if curr_epoch >= 0 and \"epoch\" in losses.columns:\n",
        "            losses = losses[losses[\"epoch\"] <= curr_epoch].copy()\n",
        "    else:\n",
        "        losses = pd.DataFrame()\n",
        "\n",
        "    # ---- training loop ----\n",
        "    for epoch in tqdm.tqdm(range(curr_epoch + 1, num_epochs), desc=\"Epochs\"):\n",
        "        tr_loss, lr, norm = train_epoch(\n",
        "            network,\n",
        "            train_dl,\n",
        "            optimizer,\n",
        "            input_label=\"cort\",\n",
        "            loss_fn=criterion_train,\n",
        "            update=True,\n",
        "            log_norm=True,\n",
        "            scheduler=scheduler,\n",
        "            per_step=True\n",
        "        )\n",
        "\n",
        "        val_metrics = eval_model(\n",
        "            network,\n",
        "            val_dl,\n",
        "            loss_fns={\n",
        "                \"huber\": nn.HuberLoss(delta=delta, reduction=\"none\"),\n",
        "                \"mae\": lambda pred, age: th.abs(pred - age) * 100\n",
        "            }\n",
        "        )\n",
        "\n",
        "        # extract scalar means/stds\n",
        "        def _to_float(x):\n",
        "            try:\n",
        "                return float(x.item())\n",
        "            except Exception:\n",
        "                return float(x)\n",
        "\n",
        "        val_row = {\n",
        "            \"fold\": i,\n",
        "            \"epoch\": epoch,\n",
        "            \"tr_huber\": float(tr_loss),\n",
        "        }\n",
        "        for k, v in val_metrics.items():\n",
        "            val_row[f\"val_{k}_mean\"] = _to_float(v[\"mean\"])\n",
        "            val_row[f\"val_{k}_std\"]  = _to_float(v[\"std\"])\n",
        "\n",
        "        tqdm.tqdm.write(\n",
        "            f\"ep. {epoch+1}/{num_epochs} | \"\n",
        "            f\"tr_loss {tr_loss:.4f} | \"\n",
        "            f\"val_mae {val_metrics['mae']['mean']:.4f} | \"\n",
        "            f\"best_val_MAE {best_val_mae} | \"\n",
        "            f\"lr {lr}\"\n",
        "        )\n",
        "\n",
        "        # Save best checkpoint per fold (by val MAE)\n",
        "        if val_row[\"val_mae_mean\"] < best_val_mae:\n",
        "            best_val_mae = val_row[\"val_mae_mean\"]\n",
        "            # print(f\"[Fold {i}] New lowest MAE: {best_val_mae:.3f}. Saving checkpoint.\")\n",
        "            checkpoint = {\n",
        "                \"epoch\": epoch,\n",
        "                \"model_state_dict\": network.state_dict(),\n",
        "                \"optimizer_state_dict\": optimizer.state_dict(),\n",
        "                \"best_val_mae\": best_val_mae,\n",
        "                \"fold\": i,\n",
        "                \"exp_name\": exp_name\n",
        "            }\n",
        "            th.save(checkpoint, ckpt_path)\n",
        "\n",
        "        # Append and persist per-fold results\n",
        "        losses = pd.concat([losses, pd.DataFrame([val_row])], ignore_index=True)\n",
        "        losses.to_csv(results_path, index=False)\n",
        "\n",
        "    try:\n",
        "        fold_df = pd.read_csv(results_path)\n",
        "        best_idx = fold_df[\"val_mae_mean\"].idxmin()\n",
        "        best_row = fold_df.loc[int(best_idx)].to_dict()\n",
        "        cv_best_rows.append(best_row)\n",
        "        save_fold_summary(cv_best_rows, summary_path)\n",
        "        print(f\"[Fold {i}] Best MAE: {best_row['val_mae_mean']:.3f} at epoch {int(best_row['epoch'])+1}\")\n",
        "    except Exception as e:\n",
        "        print(f\"[Fold {i}] Could not compute CV summary: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "5cb26fc9",
      "metadata": {},
      "outputs": [],
      "source": [
        "train_dl, test_dl, scaler = get_loaders_thk(\n",
        "    train_set,\n",
        "    test_set,\n",
        "    labels_features,\n",
        "    age_transforms=lambda x: x/255.,\n",
        "    batch_size=32\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "ec3c410a",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 16/16 [00:00<00:00, 186.74it/s]\n",
            "100%|██████████| 16/16 [00:00<00:00, 194.83it/s]\n",
            "100%|██████████| 16/16 [00:00<00:00, 177.12it/s]4it/s]\n",
            "100%|██████████| 16/16 [00:00<00:00, 179.01it/s]\n",
            "100%|██████████| 16/16 [00:00<00:00, 183.27it/s]0it/s]\n",
            "100%|██████████| 16/16 [00:00<00:00, 195.92it/s]\n",
            "100%|██████████| 16/16 [00:00<00:00, 185.09it/s]8it/s]\n",
            "100%|██████████| 16/16 [00:00<00:00, 214.88it/s]\n",
            "100%|██████████| 16/16 [00:00<00:00, 233.54it/s]6it/s]\n",
            "100%|██████████| 16/16 [00:00<00:00, 202.65it/s]\n",
            "100%|██████████| 16/16 [00:00<00:00, 201.00it/s]03it/s]\n",
            "100%|██████████| 16/16 [00:00<00:00, 201.94it/s]\n",
            "100%|██████████| 16/16 [00:00<00:00, 224.13it/s]07it/s]\n",
            "100%|██████████| 16/16 [00:00<00:00, 197.48it/s]\n",
            "100%|██████████| 16/16 [00:00<00:00, 225.88it/s]27it/s]\n",
            "100%|██████████| 16/16 [00:00<00:00, 209.31it/s]\n",
            "100%|██████████| 16/16 [00:00<00:00, 203.84it/s]51it/s]\n",
            "100%|██████████| 16/16 [00:00<00:00, 195.11it/s]\n",
            "100%|██████████| 16/16 [00:00<00:00, 231.91it/s]37it/s]\n",
            "100%|██████████| 16/16 [00:00<00:00, 231.59it/s]\n",
            "Epochs: 100%|██████████| 20/20 [00:01<00:00, 12.21it/s]\n"
          ]
        }
      ],
      "source": [
        "network = MLPCort(\n",
        "        in_dim=len(labels_features),\n",
        "        hidden=[32,64,16],\n",
        "        dropout=0.3\n",
        ").to(device=device)\n",
        "optimizer = th.optim.AdamW(network.parameters(), lr=1e-3)\n",
        "\n",
        "scheduler, warm_steps = build_scheduler(\n",
        "    optimizer=optimizer,\n",
        "    train_dl=train_dl,\n",
        "    max_lr=1e-2,\n",
        "    base_lr=1e-4,\n",
        "    warmup_epochs=warmup_epochs\n",
        ")\n",
        "\n",
        "for epoch in tqdm.tqdm(range(20), desc=\"Epochs\"):\n",
        "    tr_loss, lr, norm = train_epoch(\n",
        "        network,\n",
        "        train_dl,\n",
        "        optimizer,\n",
        "        input_label=\"cort\",\n",
        "        loss_fn=criterion_train,\n",
        "        update=True,\n",
        "        log_norm=True,\n",
        "        scheduler=scheduler,\n",
        "        per_step=True\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6dcc126",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0482, device='cuda:0')\n",
            "tensor(0.0484, device='cuda:0')\n",
            "tensor(0.0141, device='cuda:0')\n",
            "Test:\n",
            "mse: 0.002 ± 0.002\n",
            "mae: 4.724 ± 2.825\n"
          ]
        }
      ],
      "source": [
        "test_losses = eval_model(network, test_dl, loss_fns={\n",
        "        \"mse\": nn.HuberLoss(reduction='none', delta=delta), \"mae\": lambda pred, age: th.abs(pred-age)*100\n",
        "    })\n",
        "print(f'Test:')\n",
        "for k, v in test_losses.items():\n",
        "    print(f'{k}: {v[\"mean\"]:.3f} ± {v[\"std\"]:.3f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "b4da1dd3",
      "metadata": {},
      "outputs": [],
      "source": [
        "checkpoint = {\n",
        "    \"model_state_dict\": network.state_dict()\n",
        "}\n",
        "th.save(checkpoint, \"../checkpoints/MLPCort_best_model.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a44f0b5",
      "metadata": {},
      "source": [
        "Do you see something funny? :)\n",
        "I should do also hyperparameter tuning but I will skip it for time reason..."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "myenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
